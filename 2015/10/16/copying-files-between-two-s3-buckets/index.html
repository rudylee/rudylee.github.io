
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Copying Files Between Two S3 Buckets - Blog Rudy Lee</title>
  <meta name="author" content="Rudy Lee">

  
  <meta name="description" content="Copying Files Between Two S3 Buckets Oct 16th, 2015 Today, I have to copy files from one S3 bucket to another S3 bucket which sitting in separate &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.rudylee.com/2015/10/16/copying-files-between-two-s3-buckets">
  <link href="/favicon.ico" rel="icon">
  <link href='http://fonts.googleapis.com/css?family=Quicksand:300,400' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300' rel='stylesheet' type='text/css'>
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Blog Rudy Lee" type="application/atom+xml">
  <script src="/js/jquery.js"></script>
  <script src="/js/bootstrap-collapse.js"></script>
  <script src="/js/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-10301272-8']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


  <script type="text/javascript">
  window.heap=window.heap||[],heap.load=function(t,e){window.heap.appid=t,window.heap.config=e;var a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=("https:"===document.location.protocol?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+t+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(t){return function(){heap.push([t].concat(Array.prototype.slice.call(arguments,0)))}},p=["clearEventProperties","identify","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
  heap.load("1170192688");
</script>

  <!-- start Mixpanel --><script type="text/javascript">(function(e,b){if(!b.__SV){var a,f,i,g;window.mixpanel=b;b._i=[];b.init=function(a,e,d){function f(b,h){var a=h.split(".");2==a.length&&(b=b[a[0]],h=a[1]);b[h]=function(){b.push([h].concat(Array.prototype.slice.call(arguments,0)))}}var c=b;"undefined"!==typeof d?c=b[d]=[]:d="mixpanel";c.people=c.people||[];c.toString=function(b){var a="mixpanel";"mixpanel"!==d&&(a+="."+d);b||(a+=" (stub)");return a};c.people.toString=function(){return c.toString(1)+".people (stub)"};i="disable time_event track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config people.set people.set_once people.increment people.append people.union people.track_charge people.clear_charges people.delete_user".split(" ");
for(g=0;g<i.length;g++)f(c,i[g]);b._i.push([a,e,d])};b.__SV=1.2;a=e.createElement("script");a.type="text/javascript";a.async=!0;a.src="undefined"!==typeof MIXPANEL_CUSTOM_LIB_URL?MIXPANEL_CUSTOM_LIB_URL:"file:"===e.location.protocol&&"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js".match(/^\/\//)?"https://cdn.mxpnl.com/libs/mixpanel-2-latest.min.js":"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js";f=e.getElementsByTagName("script")[0];f.parentNode.insertBefore(a,f)}})(document,window.mixpanel||[]);
mixpanel.init("61a006900f814889fdc104eecb397ac0");</script><!-- end Mixpanel -->

</head>

<body   >
  <div class="navbar navbar-inverse navbar-static-top">
  	<div class="navbar-inner">
  	  <div class="container">
        <a class="btn btn-navbar" data-toggle="collapse" data-target=".navbar-responsive-collapse">
          <span class="fui-menu-24"></span>
        </a>
  	  	<div class="nav-collapse collapse navbar-responsive-collapse" style="height:0;">
  	      <ul class="nav">
    
        <li ><a href="/">Home</a></li>
    
        <li ><a href="/archives">Archives</a></li>
    
</ul>

<ul class="nav pull-right">
    
    <li><a href="http://github.com/rudylee" title="Github Profile"><i class="icon-github-sign social-navbar"></i></a></li>
    
    
    
    <li><a href="http://twitter.com/rudylee88" title="Twitter Profile"><i class="icon-twitter-sign social-navbar"></i></a></li>
    
    
    
    
</ul>

  	    </div>
  	  </div>
  	</div>
  </div>
  <div class="container" id="main">
    <div class="span12">
      <div class="row-fluid">
        <div id="content">
          <div>
<article class="hentry" role="article">
  

  <header>
  <div class="jumbotron">
    Copying Files Between Two S3 Buckets
	<h5>








  


<i class="icon-calendar-empty"></i> <time datetime="2015-10-16T12:00:00+11:00" pubdate data-updated="true">Oct 16<span>th</span>, 2015</time></h5>
  </div>
</header>
  <div class="row-fluid">
    <div class="span12">
      <p>Today, I have to copy files from one S3 bucket to another S3 bucket which sitting in separate AWS account.</p>

<p>Initially, I was thinking to use S3 clients ( Tranmit or Cyberduck ) to download the files first and manually upload the files again to the other S3 Bucket. However, this approach will consume a lot of bandwidth and really slow if you have a lot of files in your S3 bucket.</p>

<p>After a bit of research, I found that you can easily copy files between two S3 buckets. You can use either s4cmd or AWS CLI.</p>

<h2>s3cmd or s4cmd</h2>

<p>Run this command to install s4cmd</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>pip install s4cmd
</span></code></pre></td></tr></table></div></figure>


<p>After you finished setting up the AWS credentials, you can start the copying process.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># format</span>
</span><span class='line'>s4cmd cp s3://&lt;<span class="nb">source</span>-bucket&gt; s3://&lt;target-bucket&gt;/ --recursive
</span><span class='line'>
</span><span class='line'><span class="c">#example</span>
</span><span class='line'>s4cmd cp s3://rudylee-images s3://rudylee-new-images/ --recursive
</span></code></pre></td></tr></table></div></figure>


<h2>AWS CLI</h2>

<p>Install the cli through pip</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>pip install awscli
</span></code></pre></td></tr></table></div></figure>


<p>And configure it</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>awscli configure
</span></code></pre></td></tr></table></div></figure>


<p>The usage is quite similar to s4cmd, see below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>aws s3 cp s3://&lt;<span class="nb">source</span>-bucket&gt; s3://&lt;destination-bucket&gt;
</span></code></pre></td></tr></table></div></figure>


<p>I prefer using AWS CLI because it has more options and official support. AWS CLI has a built it support can specify the ACL and permission of the objects.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># The command below will allow the target bucket owner to have full access to the object</span>
</span><span class='line'>aws s3 cp s3://&lt;<span class="nb">source</span>-bucket&gt; s3://&lt;target-bucket&gt; --acl <span class="s2">&quot;bucket-owner-full-control&quot;</span> --recursive
</span></code></pre></td></tr></table></div></figure>


<p>Since my target bucket is sitting in separate AWS account, I have to set another permission to allow everyone to upload and delete files into my target bucket.</p>

<p>If you want to follow this approach, make sure to delete that permission after you finished with the copying.</p>

<p>The other option is to set the S3 bucket policy manually, see this link: <a href="http://serverfault.com/questions/556077/what-is-causing-access-denied-when-using-the-aws-cli-to-download-from-amazon-s3">http://serverfault.com/questions/556077/what-is-causing-access-denied-when-using-the-aws-cli-to-download-from-amazon-s3</a></p>

    </div>
  </div>



  <footer>
    <hr>
    
    <div class="row-fluid">
      
      <div class="span6">
        <p class="meta">
        
        



  <a href="/categories/aws/"><span class="badge">AWS</span></a>




        </p>
      </div>
      
      <div class="span6 social-sharing">
        <div class="sharing">
  <div class="addthis_toolbox addthis_default_style ">
  
  
  <a class="addthis_button_tweet"></a>
  
  
  <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#pubid="></script>
</div>

      </div>
      
      
    </div>
    
    <div class="row-fluid">
      <div class="span12">
        <p class="meta">
          
            <a class="basic-alignment left" href="/2015/08/31/create-ssh-tunnel-to-backup-postgresql-database/" title="Previous Post: Create SSH Tunnel To Backup PostgreSQL Database">&laquo; Create SSH Tunnel To Backup PostgreSQL Database</a>
          
          
            <a class="basic-alignment right" href="/2016/01/20/reopen-last-commit-in-git/" title="Next Post: Reopen Last Commit in Git">Reopen Last Commit in Git &raquo;</a>
          
        </p>
      </div>
    </div>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>



        </div>
      </div>
      <div class="row-fluid">
        <footer class="footer-page" role="contentinfo">
          <p>
  Copyright &copy; 2017 - Rudy Lee -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span> - Theme by <a href="http://alexgaribay.com">Alex Garibay</a>
</p>


        </footer>
      </div>
    </div>
  </div>
  

<script type="text/javascript">
      var disqus_shortname = 'blogrudylee';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://blog.rudylee.com/2015/10/16/copying-files-between-two-s3-buckets/';
        var disqus_url = 'http://blog.rudylee.com/2015/10/16/copying-files-between-two-s3-buckets/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
