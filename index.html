
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Blog Rudy Lee</title>
  <meta name="author" content="Rudy Lee">

  
  <meta name="description" content="Hi. I&#8217;m Rudy Lee. Here are some thoughts of mine. Jul 1st, 2017 New Relic Monitor Background Jobs with New Relic Query Language Background In &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.rudylee.com">
  <link href="/favicon.png" rel="icon">
  <link href='http://fonts.googleapis.com/css?family=Quicksand:300,400' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300' rel='stylesheet' type='text/css'>
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Blog Rudy Lee" type="application/atom+xml">
  <script src="/js/jquery.js"></script>
  <script src="/js/bootstrap-collapse.js"></script>
  <script src="/js/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-10301272-8']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


  <script type="text/javascript">
  window.heap=window.heap||[],heap.load=function(t,e){window.heap.appid=t,window.heap.config=e;var a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=("https:"===document.location.protocol?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+t+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(t){return function(){heap.push([t].concat(Array.prototype.slice.call(arguments,0)))}},p=["clearEventProperties","identify","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
  heap.load("1170192688");
</script>

  <!-- start Mixpanel --><script type="text/javascript">(function(e,b){if(!b.__SV){var a,f,i,g;window.mixpanel=b;b._i=[];b.init=function(a,e,d){function f(b,h){var a=h.split(".");2==a.length&&(b=b[a[0]],h=a[1]);b[h]=function(){b.push([h].concat(Array.prototype.slice.call(arguments,0)))}}var c=b;"undefined"!==typeof d?c=b[d]=[]:d="mixpanel";c.people=c.people||[];c.toString=function(b){var a="mixpanel";"mixpanel"!==d&&(a+="."+d);b||(a+=" (stub)");return a};c.people.toString=function(){return c.toString(1)+".people (stub)"};i="disable time_event track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config people.set people.set_once people.increment people.append people.union people.track_charge people.clear_charges people.delete_user".split(" ");
for(g=0;g<i.length;g++)f(c,i[g]);b._i.push([a,e,d])};b.__SV=1.2;a=e.createElement("script");a.type="text/javascript";a.async=!0;a.src="undefined"!==typeof MIXPANEL_CUSTOM_LIB_URL?MIXPANEL_CUSTOM_LIB_URL:"file:"===e.location.protocol&&"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js".match(/^\/\//)?"https://cdn.mxpnl.com/libs/mixpanel-2-latest.min.js":"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js";f=e.getElementsByTagName("script")[0];f.parentNode.insertBefore(a,f)}})(document,window.mixpanel||[]);
mixpanel.init("61a006900f814889fdc104eecb397ac0");</script><!-- end Mixpanel -->

</head>

<body   >
  <div class="navbar navbar-inverse navbar-static-top">
  	<div class="navbar-inner">
  	  <div class="container">
        <a class="btn btn-navbar" data-toggle="collapse" data-target=".navbar-responsive-collapse">
          <span class="fui-menu-24"></span>
        </a>
  	  	<div class="nav-collapse collapse navbar-responsive-collapse" style="height:0;">
  	      <ul class="nav">
    
        <li ><a href="/">Home</a></li>
    
        <li ><a href="/archives">Archives</a></li>
    
</ul>

<ul class="nav pull-right">
    
    <li><a href="http://github.com/rudylee" title="Github Profile"><i class="icon-github-sign social-navbar"></i></a></li>
    
    
    
    <li><a href="http://twitter.com/rudylee88" title="Twitter Profile"><i class="icon-twitter-sign social-navbar"></i></a></li>
    
    
    
    
</ul>

  	    </div>
  	  </div>
  	</div>
  </div>
  <div class="container" id="main">
    <div class="span12">
      <div class="row-fluid">
        <div id="content">
          <div class="jumbotron">
  <div class="container">
    Hi. I&#8217;m Rudy Lee.
    <h3 class="tagline">Here are some thoughts of mine.</h3>
  </div>
</div>


<div class="blog-index">
  
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2017-07-01T12:29:00+10:00" pubdate data-updated="true">Jul 1<span>st</span>, 2017</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/new-relic/"><span class="badge">New Relic</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2017/07/01/monitor-background-jobs-with-new-relic-query-language/">Monitor Background Jobs with New Relic Query Language</a></h1>
      <h1>Background</h1>

<p>In this blog post, I&rsquo;ll show you how to set up an alert to monitor your sidekiq jobs using New Relic Query Language and New Relic Alert.</p>

<p>I was given a task to find a solution to monitor our sidekiq jobs. In the past, I used New Relic Sidekiq Plugin ( <a href="https://newrelic.com/plugins/secondimpression/131">https://newrelic.com/plugins/secondimpression/131</a> ) to do this.</p>

<p>The plugin is a Ruby app that connects to your Redis instance, retrieves all of the sidekiq metrics such as jobs, queues and send it to New Relic using the agent library.</p>

<p>This means you need to host the Ruby app somewhere and make sure the plugin can connect to your Redis instance.</p>

<p>However, I found a much better solution using NRQL that doesn&rsquo;t require you to set up a new server or install any plugins.</p>

<h1>New Relic Query Language ( NRQL )</h1>

<p>NRQL definition from the official New Relic docs ( <a href="https://docs.newrelic.com/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql">https://docs.newrelic.com/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql</a> )</p>

<p>The New Relic Query Language (NRQL), similar to SQL, is a query language for making calls against the Insights event database. NRQL enables you to query data collected from your application and transform that data into dynamic charts. From there, you can interpret your data to better understand how your application is used in a variety of ways.</p>

<p>Using NRQL, You can run a query to get the amount of background jobs that has been executed for a specific time period.</p>

<p>Here is the query to get the count of background jobs:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SELECT count(name) FROM Transaction WHERE transactionType='Other'</span></code></pre></td></tr></table></div></figure>


<h1>New Relic Alert and NRQL</h1>

<p>First thing you have to do is to create a New Relic alert policy using NRQL. See the screenshots below:</p>

<p><a href="/images/posts/nrql-sidekiq/1.png"><img src="/images/posts/nrql-sidekiq/1.png" alt="" /></a></p>

<p><a href="/images/posts/nrql-sidekiq/2.png"><img src="/images/posts/nrql-sidekiq/2.png" alt="" /></a></p>

<p>Choose <code>NRQL</code> on the <code>Categorize</code> step</p>

<p><a href="/images/posts/nrql-sidekiq/3.png"><img src="/images/posts/nrql-sidekiq/3.png" alt="" /></a></p>

<p>And put the the following query:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SELECT count(name) FROM Transaction WHERE transactionType='Other'</span></code></pre></td></tr></table></div></figure>


<p>After that, you can set up a condition when it will fire the alert.</p>

<p>In the screenshot below, you can see that I set the alert to fire if there are no background jobs running within 15 minutes.</p>

<p><a href="/images/posts/nrql-sidekiq/4.png"><img src="/images/posts/nrql-sidekiq/4.png" alt="" /></a></p>

<p><a href="/images/posts/nrql-sidekiq/5.png"><img src="/images/posts/nrql-sidekiq/5.png" alt="" /></a></p>

<p>I hope this tutorial will give you an idea on how to monitor your background jobs.</p>

      
      
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2017-01-30T15:48:00+11:00" pubdate data-updated="true">Jan 30<span>th</span>, 2017</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/elastic-cloud/"><span class="badge">Elastic Cloud</span></a>
          
          <a href="/categories/elasticsearch/"><span class="badge">Elasticsearch</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2017/01/30/setting-up-elasticsearch-watcher-to-check-for-cluster-status-on-elastic-cloud/">Setting Up Elasticsearch Watcher to Check For Cluster Status on Elastic Cloud</a></h1>
      <p>Last week, I was busy migrating our staging and production Elasticsearch clusters from AWS Elasticsearch to Elastic Cloud. The reason behind this migration is because we need dynamic scripting feature in our application and Elastic Cloud is the only managed Elasticsearch hosting that currently supports dynamic scripting.</p>

<p>In terms of pricing, Elastic Cloud is slightly more expensive than AWS Elasticsearch. I think this is because they are using AWS EC2 under the hood. You can compare the pricing of both services here <a href="https://aws.amazon.com/elasticsearch-service/pricing/">https://aws.amazon.com/elasticsearch-service/pricing/</a> and <a href="https://www.elastic.co/cloud/as-a-service/pricing">https://www.elastic.co/cloud/as-a-service/pricing</a>.</p>

<p>As of now, Elastic Cloud supports the latest version of Elasticsearch which is 5.1.2. If you like living on the edge, I recommend you to try Elastic Cloud.</p>

<h2>Creating a watcher</h2>

<p>On AWS, we can use Cloud Watch to monitor our Elasticsearch cluster health status as well as monitoring other metrics such as memory and cpu usage. With Elastic Cloud, we have to use Elastic Watcher or Alerting to monitor and trigger alerts.</p>

<p>Currently, there is no UI to set up the watcher on Elastic Cloud. To create a watcher, you have to send a PUT request to your cluster. Please note that this blog post is based on Elasticsearch version <code>1.7.6</code> and Elasticsearch Watcher version is <code>1.0.1</code>.</p>

<p>First thing you have to do is to enable the watcher plugin on the Elastic Cloud clusters configuration. See screenshot below:</p>

<p><a href="/images/posts/elastic-cloud/enable%20elastic%20cloud%20watcher%20plugin.png"><img src="/images/posts/elastic-cloud/enable%20elastic%20cloud%20watcher%20plugin.png" alt="" /></a></p>

<p>The next thing to do is to add an alert recepient email to the Elastic Cloud whitelist. In order to do this, go to <code>Account &gt; Email settings</code> and scroll to the bottom of the page. See screenshot below:</p>

<p><a href="/images/posts/elastic-cloud/whitelist.png"><img src="/images/posts/elastic-cloud/whitelist.png" alt="" /></a></p>

<p>Shortly after that, you will receive an email to confirm this request for whitelist. Confirm the request and you are ready to receive email from Elastic Cloud.</p>

<p>Now open up your REST client app or if you are one of those CLI Guru, you can stick with CURL. As I mentioned earlier, we will send a PUT request to our cluster to create a watcher.</p>

<p>The endpoint of the request is something like this <code>http://elastic-cloud-username:elastic-cloud-password@elastic-cloud-cluster-host:9200/_watcher/watch/cluster_health_watch</code></p>

<p>You have to replace <code>elastic-cloud-username</code>, <code>elastic-cloud-password</code> and <code>elastic-cloud-cluster-host</code> with your cluster details.</p>

<p>And here is the JSON content of the request: ( please replace the host, auth username, auth password and to email with your cluster details )</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "trigger" : {
</span><span class='line'>    "schedule" : { "interval" : "10s" }
</span><span class='line'>  },
</span><span class='line'>  "input" : {
</span><span class='line'>    "http" : {
</span><span class='line'>      "request" : {
</span><span class='line'>       "host" : "add-your-elastic-cloud-host-here",
</span><span class='line'>       "port" : 9200,
</span><span class='line'>       "path" : "/_cluster/health",
</span><span class='line'>       "auth" : {
</span><span class='line'>          "basic" : {
</span><span class='line'>            "username" : "your-elastic-cloud-username",
</span><span class='line'>            "password" : "your-elastic-cloud-password"
</span><span class='line'>          }
</span><span class='line'>        }
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>  },
</span><span class='line'>  "condition" : {
</span><span class='line'>    "compare" : {
</span><span class='line'>      "ctx.payload.status" : { "eq" : "red" }
</span><span class='line'>    }
</span><span class='line'>  },
</span><span class='line'>  "actions" : {
</span><span class='line'>    "send_email" : {
</span><span class='line'>      "email" : {
</span><span class='line'>        "to" : "the-recepient-email-address",
</span><span class='line'>        "subject" : "Cluster Status Warning",
</span><span class='line'>        "body" : "Cluster status is RED"
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>In a nutshell, the request above will create a watcher that will get triggered every 10s, gets the input from our Elasticsearch <code>/_cluster/health</code> page, checks for cluster status ( see condition section ) and sends an email if the condition is matched.</p>

<p>Here is the screenshot of my PUT request using <a href="https://insomnia.rest/">Insomnia REST Client</a>:</p>

<p>After sending the request, we can confirm if the watcher is created successfully or not by visiting this endpoint on our browser <code>http://elasticsearch-cluster-host:9200/_watcher/watch/cluster_health_watch</code></p>

<p>If the watcher is created successfully, you should see a response like this:</p>

<p><a href="/images/posts/elastic-cloud/insomnia%20put%20request.png"><img src="/images/posts/elastic-cloud/insomnia%20put%20request.png" alt="" /></a></p>

<h2>Delete the watcher</h2>

<p>You can send a DELETE request if you want to delete the watcher</p>

<p><code>curl -XDELETE http://elasticsearch-cluster-host:9200/_watcher/watch/cluster_health_watch</code></p>

<h2>Check if your watcher was triggered</h2>

<p>You can check if your watcher has been triggered by sending a GET request to <code>/.watch_history*/search?pretty</code> with the following query:</p>

<p><a href="/images/posts/elastic-cloud/watcher%20response.png"><img src="/images/posts/elastic-cloud/watcher%20response.png" alt="" /></a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "query" : {
</span><span class='line'>    "match" : { "result.condition.met" : true }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>If the query returns a hit, it means that your watcher has been triggered. This is helpful during debugging.</p>

<p>That&rsquo;s it for now, the next thing I need to figure out is to create alerting for CPU and memory usage. I&rsquo;ll leave it for another blog post.</p>

      
      
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2017-01-11T19:41:00+11:00" pubdate data-updated="true">Jan 11<span>th</span>, 2017</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/l2tp/"><span class="badge">L2TP</span></a>
          
          <a href="/categories/unix-and-linux/"><span class="badge">Unix and Linux</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2017/01/11/setting-up-l2tp-vpn-to-bypass-great-firewall-of-china/">Setting Up L2TP VPN to Bypass Great Firewall Of China</a></h1>
      <p>Last month, I traveled to China for the second time. Unlike my first trip, this time I am more prepared to bypass the great firewall of China.</p>

<p>During my first trip in China, I was mainly relying on simple SSH tunnel to get access to Gmail and all other blocked services. This solution is unrealiable because I couldn&rsquo;t use it on my Android phone. Aside from that, I also kept having constant dropouts which explained in this blog post <a href="http://blog.zorinaq.com/my-experience-with-the-great-firewall-of-china/">http://blog.zorinaq.com/my-experience-with-the-great-firewall-of-china/</a></p>

<p>After an extensive research and also a recommendation from one of my friends, I decided to install an L2TP VPN server in Japan. I choose Japan because it&rsquo;s close to China and I can use Tokyo AWS Region.</p>

<p>I ended up using this ansible playbook that I found when I was looking for tutorials <a href="https://github.com/jlund/streisand">https://github.com/jlund/streisand</a>. It&rsquo;s basically an Ansible Playbook which help you to install various software such as OpenVPN, L2TP, Tor, etc. You just need to run one shell script and it will install all of those software to your target host.</p>

<h3>Running the playbook</h3>

<p>Since I already have ansible installed, I just need to clone the project and run the setup script. If not a complete tutorial on how to get started you can check this installation guide here <a href="https://github.com/jlund/streisand#installation">https://github.com/jlund/streisand#installation</a>.</p>

<p>Cloning the project</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/jlund/streisand.git && cd streisand</span></code></pre></td></tr></table></div></figure>


<p>Running the setup script</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./streisand</span></code></pre></td></tr></table></div></figure>


<p>When you run the setup script, it will ask few questions such as where to host the server, AWS Access Keys, etc. I am using AWS because I can use the free tier to run the VPN server. On AWS, it will take around 45 minutes to finish the whole installation process.</p>

<h3>Using the VPN</h3>

<p>When the whole installation finished, the playbook will create instructions files in the server. You need to SSH to the server in order to view the instruction.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh ubuntu@server-ip</span></code></pre></td></tr></table></div></figure>


<p>Go to the NGINX folder to see file</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /var/www/streisand/l2tp-ipsec</span></code></pre></td></tr></table></div></figure>


<p>Read the instruction</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat index.md | more</span></code></pre></td></tr></table></div></figure>


<p>In the file, you will find instructions on how to connect to the L2TP server all different operating systems.</p>

      
      
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2016-12-05T13:51:00+11:00" pubdate data-updated="true">Dec 5<span>th</span>, 2016</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/haproxy/"><span class="badge">HAProxy</span></a>
          
          <a href="/categories/unix-and-linux/"><span class="badge">Unix and Linux</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2016/12/05/haproxy-as-a-reverse-proxy-for-cloudinary-images/">HAProxy as a reverse proxy for cloudinary images</a></h1>
      <p>We are using in one of our applications <a href="http://cloudinary.com/">Cloudinary</a> to host and resize images on the fly. We are also using <a href="http://www.cloudflare.com">Cloudflare</a> for our CDN and DNS management.</p>

<p>I was given a task to setup a CNAME subdomain in CloudFlare to forward the request to Cloudinary. This way we can still have the benefit of serving static images from CDN as well as reducing the Cloudinary bandwidth usage.</p>

<p>My solution is to set HAProxy as a reverse proxy which responsible to fetch images from Cloudinary server. You can see the overview diagram below:</p>

<p><a href="/images/posts/HAProxy-as-a-reverse-proxy.png"><img src="/images/posts/HAProxy-as-a-reverse-proxy.png" alt="" /></a></p>

<p>The first thing we have to do is to create an ACL in HAProxy for our cloudinary subdomain</p>

<p>In the configuration below, we are telling HAProxy to forward all requests from <code>cloudinary-asset.rudylee.com</code> to <code>cloudinary-backend</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>listen  http
</span><span class='line'>        bind 127.0.0.1:8080
</span><span class='line'>        maxconn     18000
</span><span class='line'>
</span><span class='line'>        acl host_cloudinary hdr(host) -i cloudinary-asset.rudylee.com
</span><span class='line'>
</span><span class='line'>        use_backend cloudinary-backend if host_cloudinary</span></code></pre></td></tr></table></div></figure>


<p>Next one is to create a new backend.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>backend cloudinary-backend
</span><span class='line'>        http-request set-header Host res.cloudinary.com
</span><span class='line'>        server cloudinary res.cloudinary.com:80</span></code></pre></td></tr></table></div></figure>


<p>Restart HAProxy and you should be able to use the subdomain to serve images from Cloudinary (eg: <a href="http://cloudinary-asset.rudylee.com/rudylee/image/upload/12298848/icon/12379593943923.png">http://cloudinary-asset.rudylee.com/rudylee/image/upload/12298848/icon/12379593943923.png</a> )</p>

<p>Requesting the images through SSL should work if you have SSL termination configured in your HAProxy.</p>

      
      
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2016-04-13T15:59:00+10:00" pubdate data-updated="true">Apr 13<span>th</span>, 2016</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/unix-and-linux/"><span class="badge">Unix and Linux</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2016/04/13/haproxy-and-a-slash-b-testing/">HAProxy and A/B Testing</a></h1>
      <p>Few weeks ago, I was given a task to create an A/B test using HAProxy. I need to make HAProxy to split traffic between two different applications ( Rails and NodeJS )</p>

<p>In this blog post, I&rsquo;ll explain how to achieve this.</p>

<h3>Create ACL for the page you want to A/B test</h3>

<p>The first step you have to do is to create an ACL for the URL you want to A/B test. In this example, the URL path is <code>/ab-test-path</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>acl ab_test_url path_beg /ab-test-path</span></code></pre></td></tr></table></div></figure>


<h3>Direct the traffic based on ACL rule and cookie</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Send user to first backend if they have SITEID cookie with cookie_first_backend value
</span><span class='line'>use_backend first-backend if { req.cook(SITEID) -m beg cookie_first_backend }
</span><span class='line'>
</span><span class='line'># Send user to second backend if they have SITEID cookie with cookie_second_backend value and the URL they request is ab_test_url
</span><span class='line'>use_backend second-backend if { req.cook(SITEID) -m beg cookie_second_backend } ab_test_url
</span><span class='line'>
</span><span class='line'># If the doesn't have any cookie send them to ab-test backend
</span><span class='line'>use_backend ab-test-backend if ab_test_url
</span><span class='line'>
</span><span class='line'># By default send all traffic to the first backend
</span><span class='line'>default_backend first-backend</span></code></pre></td></tr></table></div></figure>


<h3>Create all the backends</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>backend first-backend
</span><span class='line'>        appsession JSESSIONID len 52 timeout 3h
</span><span class='line'>        cookie SERVERID insert
</span><span class='line'>
</span><span class='line'>        balance leastconn
</span><span class='line'>        server  backend02a-aws-syd 10.0.105.102:80 check maxconn 3000 inter 30s
</span><span class='line'>        server  backend02b-aws-syd 10.0.106.102:80 check maxconn 3000 inter 30s
</span><span class='line'>
</span><span class='line'>backend second-backend
</span><span class='line'>        server  backend03a-aws-syd 10.0.105.103:80 check maxconn 3000 inter 30s
</span><span class='line'>
</span><span class='line'>backend ab-test-backend
</span><span class='line'>        balance roundrobin
</span><span class='line'>        cookie SITEID insert indirect nocache maxlife 48h
</span><span class='line'>
</span><span class='line'>        server backend02a-aws-syd 10.0.105.102:80 weight 25 cookie cookie_first_backend
</span><span class='line'>        server backend02b-aws-syd 10.0.106.102:80 weight 25 cookie cookie_first_backend
</span><span class='line'>
</span><span class='line'>        server backend03a-aws-syd 10.0.105.103:80 weight 50 cookie cookie_second_backend</span></code></pre></td></tr></table></div></figure>


<p>The final HAProxy config should be something like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>listen  http 127.0.0.1:8080
</span><span class='line'>        maxconn     18000
</span><span class='line'>
</span><span class='line'>        # A/B Test ACLs
</span><span class='line'>        acl ab_test_url path_beg /ab-test-path
</span><span class='line'>
</span><span class='line'>        use_backend first-backend if { req.cook(SITEID) -m beg cookie_first_backend }
</span><span class='line'>        use_backend second-backend if { req.cook(SITEID) -m beg cookie_second_backend } ab_test_url
</span><span class='line'>        use_backend ab-test-backend if ab_test_url
</span><span class='line'>
</span><span class='line'>        default_backend first-backend
</span><span class='line'>
</span><span class='line'>backend first-backend
</span><span class='line'>        appsession JSESSIONID len 52 timeout 3h
</span><span class='line'>        cookie SERVERID insert
</span><span class='line'>
</span><span class='line'>        balance leastconn
</span><span class='line'>        server  backend02a-aws-syd 10.0.105.102:80 check maxconn 3000 inter 30s
</span><span class='line'>        server  backend02b-aws-syd 10.0.106.102:80 check maxconn 3000 inter 30s
</span><span class='line'>
</span><span class='line'>backend second-backend
</span><span class='line'>        server  backend03a-aws-syd 10.0.105.103:80 check maxconn 3000 inter 30s
</span><span class='line'>
</span><span class='line'>backend ab-test-backend
</span><span class='line'>        balance roundrobin
</span><span class='line'>        cookie SITEID insert indirect nocache maxlife 48h
</span><span class='line'>
</span><span class='line'>        server backend02a-aws-syd 10.0.105.102:80 weight 25 cookie cookie_first_backend
</span><span class='line'>        server backend02b-aws-syd 10.0.106.102:80 weight 25 cookie cookie_first_backend
</span><span class='line'>
</span><span class='line'>        server backend03a-aws-syd 10.0.105.103:80 weight 50 cookie cookie_second_backend</span></code></pre></td></tr></table></div></figure>


      
      
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2016-03-09T14:55:00+11:00" pubdate data-updated="true">Mar 9<span>th</span>, 2016</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/aws/"><span class="badge">AWS</span></a>
          
          <a href="/categories/linux/"><span class="badge">Linux</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2016/03/09/create-new-user-on-amazon-ami-and-give-it-root-access/">Create new user on Amazon AMI and give it root access</a></h1>
      <p>Setup your new EC2 instance on AWS and choose Amazon AMI.</p>

<p>SSH to your instance using your private key</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh -i &lt;path-to-your-pem-file&gt; ec2-user@&lt;ec2-endpoint-or-ip&gt;</span></code></pre></td></tr></table></div></figure>


<p>Change to root</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo su</span></code></pre></td></tr></table></div></figure>


<p>Create new group for your user ( in this case my group name is &lsquo;dev&rsquo; )</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>groupadd dev</span></code></pre></td></tr></table></div></figure>


<p>Create new user and assign it to your recently created group</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>useradd -g dev dev</span></code></pre></td></tr></table></div></figure>


<p>Give the username root access</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>visudo</span></code></pre></td></tr></table></div></figure>


<p>Add this to the bottom of the file</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dev     ALL=(ALL)       NOPASSWD:ALL</span></code></pre></td></tr></table></div></figure>


<p>Delete the password for &lsquo;dev&rsquo; user</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo passwd dev -d</span></code></pre></td></tr></table></div></figure>


<p>Change to the &lsquo;dev&rsquo; user</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>su dev</span></code></pre></td></tr></table></div></figure>


<p>Try run sudo su whether you can gain root privileges</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo su</span></code></pre></td></tr></table></div></figure>


<p>Change user back to dev and set authorized_keys for ssh</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>exit
</span><span class='line'>mkdir ~/.ssh
</span><span class='line'>vi ~/.ssh/authorized_keys
</span><span class='line'>chmod -R 700 ~/.ssh</span></code></pre></td></tr></table></div></figure>


<p>If everything is correct, you should be able to change to root user from dev without providing any password.</p>

      
      
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2016-02-16T16:14:00+11:00" pubdate data-updated="true">Feb 16<span>th</span>, 2016</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/elasticsearch/"><span class="badge">Elasticsearch</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2016/02/16/import-json-to-elasticsearch-using-jq/">Import JSON to Elasticsearch using jq</a></h1>
      <p>This is based on <a href="http://kevinmarsh.com/2014/10/23/using-jq-to-import-json-into-elasticsearch.html">http://kevinmarsh.com/2014/10/23/using-jq-to-import-json-into-elasticsearch.html</a></p>

<p>Install jq first on Mac</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>brew install jq</span></code></pre></td></tr></table></div></figure>


<p>Import the JSON file to Elasticsearch index</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat file.json | jq -c '.[] | {"index": {"_index": "bookmarks", "_type": "bookmark", "_id": .id}}, .' | curl -XPOST localhost:9200/_bulk --data-binary @-</span></code></pre></td></tr></table></div></figure>


<p>Check for the list of indexes <a href="http://localhost:9200/_cat/indices?v">http://localhost:9200/_cat/indices?v</a></p>

<p>See the list of records <a href="http:/localhost:9200//bookmarks/_search">http:/localhost:9200//bookmarks/_search</a></p>

      
      
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2016-01-20T14:26:00+11:00" pubdate data-updated="true">Jan 20<span>th</span>, 2016</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/git/"><span class="badge">Git</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2016/01/20/reopen-last-commit-in-git/">Reopen Last Commit in Git</a></h1>
      <p>Run the command below if you want to reopen the last commit in your git</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git reset --soft HEAD~
</span></code></pre></td></tr></table></div></figure>


<p>This is useful if you miss something in your last commit. Instead of creating new commit and squashing it, you can open last commit and fix it there.</p>

      
      
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2015-10-16T12:00:00+11:00" pubdate data-updated="true">Oct 16<span>th</span>, 2015</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/aws/"><span class="badge">AWS</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2015/10/16/copying-files-between-two-s3-buckets/">Copying Files Between Two S3 Buckets</a></h1>
      <p>Today, I have to copy files from one S3 bucket to another S3 bucket which sitting in separate AWS account.</p>

<p>Initially, I was thinking to use S3 clients ( Tranmit or Cyberduck ) to download the files first and manually upload the files again to the other S3 Bucket. However, this approach will consume a lot of bandwidth and really slow if you have a lot of files in your S3 bucket.</p>

<p>After a bit of research, I found that you can easily copy files between two S3 buckets. You can use either s4cmd or AWS CLI.</p>

<h2>s3cmd or s4cmd</h2>

<p>Run this command to install s4cmd</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>pip install s4cmd
</span></code></pre></td></tr></table></div></figure>


<p>After you finished setting up the AWS credentials, you can start the copying process.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># format</span>
</span><span class='line'>s4cmd cp s3://&lt;<span class="nb">source</span>-bucket&gt; s3://&lt;target-bucket&gt;/ --recursive
</span><span class='line'>
</span><span class='line'><span class="c">#example</span>
</span><span class='line'>s4cmd cp s3://rudylee-images s3://rudylee-new-images/ --recursive
</span></code></pre></td></tr></table></div></figure>


<h2>AWS CLI</h2>

<p>Install the cli through pip</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>pip install awscli
</span></code></pre></td></tr></table></div></figure>


<p>And configure it</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>awscli configure
</span></code></pre></td></tr></table></div></figure>


<p>The usage is quite similar to s4cmd, see below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>aws s3 cp s3://&lt;<span class="nb">source</span>-bucket&gt; s3://&lt;destination-bucket&gt;
</span></code></pre></td></tr></table></div></figure>


<p>I prefer using AWS CLI because it has more options and official support. AWS CLI has a built it support can specify the ACL and permission of the objects.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># The command below will allow the target bucket owner to have full access to the object</span>
</span><span class='line'>aws s3 cp s3://&lt;<span class="nb">source</span>-bucket&gt; s3://&lt;target-bucket&gt; --acl <span class="s2">&quot;bucket-owner-full-control&quot;</span> --recursive
</span></code></pre></td></tr></table></div></figure>


<p>Since my target bucket is sitting in separate AWS account, I have to set another permission to allow everyone to upload and delete files into my target bucket.</p>

<p>If you want to follow this approach, make sure to delete that permission after you finished with the copying.</p>

<p>The other option is to set the S3 bucket policy manually, see this link: <a href="http://serverfault.com/questions/556077/what-is-causing-access-denied-when-using-the-aws-cli-to-download-from-amazon-s3">http://serverfault.com/questions/556077/what-is-causing-access-denied-when-using-the-aws-cli-to-download-from-amazon-s3</a></p>

      
      
    </div>
  </div>



    </article>
    
    <hr>
    
  
  
    <article>
      

  <div class="row-fluid">
    <div class="span2">
		<h1 class="date-time">








  


<i class="icon-calendar-empty"></i> <time datetime="2015-08-31T10:28:00+10:00" pubdate data-updated="true">Aug 31<span>st</span>, 2015</time></h5>
          <div class="row-fluid">
          
          </div>
          
          <div class="row-fluid">
          
          <a href="/categories/postgresql/"><span class="badge">PostgreSQL</span></a>
          
          <a href="/categories/unix-and-linux/"><span class="badge">Unix and Linux</span></a>
          
          </div>
          
    </div>
    <div class="span10">
      <h1 class="link"><a href="/2015/08/31/create-ssh-tunnel-to-backup-postgresql-database/">Create SSH Tunnel To Backup PostgreSQL Database</a></h1>
      <p>Today, I was trying to create a backup of production database. The problem is we have two different version of PostgreSQL running on production and these databases can only be accessed from front end(FE) server. We have older version of PostgreSQL client installed in all FE server which means I can&rsquo;t use it to run pg_dump.</p>

<h2>SSH Tunnel to the rescue</h2>

<p>One solution to this problem is to create a SSH tunnel. Since I have the latest version of PostgreSQL client installed in my machine, I can run pg_dump locally which will connect to the database through SSH tunnel.</p>

<p>Here is the command I used to create SSH tunnel:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Format: ssh -L &lt;local-port&gt;:&lt;db-hostname&gt;:&lt;db-port&gt; &lt;fe-username&gt;@&lt;fe-hostname&gt;</span>
</span><span class='line'>ssh -L 9000:database.com:5432 ubuntu@production.servers.com
</span></code></pre></td></tr></table></div></figure>


<p>After this you can check whether the SSH tunnel is succesfully created by running this and look for port 9000</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>netstat -na | grep LISTEN
</span></code></pre></td></tr></table></div></figure>


<p>If you confirm that the SSH tunnel is working, you can run psql to connect or pg_dump to backup your database</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>psql -h localhost -p 9000
</span></code></pre></td></tr></table></div></figure>


      
      
    </div>
  </div>



    </article>
    
  
  <div class="pagination">
    
    <a class="prev" href="/page/2/">&larr; Older</a>
    

    
  </div>
</div>


        </div>
      </div>
      <div class="row-fluid">
        <footer class="footer-page" role="contentinfo">
          <p>
  Copyright &copy; 2017 - Rudy Lee -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span> - Theme by <a href="http://alexgaribay.com">Alex Garibay</a>
</p>


        </footer>
      </div>
    </div>
  </div>
  

<script type="text/javascript">
      var disqus_shortname = 'blogrudylee';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
